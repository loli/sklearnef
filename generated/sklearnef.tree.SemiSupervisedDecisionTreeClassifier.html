<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8">
    
    <title>sklearnef.tree.SemiSupervisedDecisionTreeClassifier &mdash; sklearnef 0.1.dev documentation</title>
    
    <link rel="stylesheet" type="text/css" href="../_static/css/spc-bootstrap.css">
    <link rel="stylesheet" type="text/css" href="../_static/css/spc-extend.css">
    <link rel="stylesheet" href="../_static/scipy.css" type="text/css" >
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" >
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.1.dev',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="../_static/js/copybutton.js"></script>
    <link rel="top" title="sklearnef 0.1.dev documentation" href="../index.html" >
    <link rel="next" title="sklearnef.tree.GoodnessOfFit" href="sklearnef.tree.GoodnessOfFit.html" >
    <link rel="prev" title="sklearnef.tree.DensityTree.transform" href="generated/sklearnef.tree.DensityTree.transform.html" > 
  </head>
  <body>

  <div class="container">
    <div class="header">
    </div>
  </div>


    <div class="container">
      <div class="main">
        
	<div class="row-fluid">
	  <div class="span12">
	    <div class="spc-navbar">
              
    <ul class="nav nav-pills pull-left">
        <li class="active"><a href="https://github.com/loli/sklearnef/">GitHub</a></li>
        <li class="active"><a href="https://pypi.python.org/pypi/sklearnef/">PyPi</a></li>
	
        <li class="active"><a href="../index.html">sklearnef 0.1.dev documentation</a></li>
	 
    </ul>
              
              
    <ul class="nav nav-pills pull-right">
      <li class="active">
        <a href="../genindex.html" title="General Index"
           accesskey="I">index</a>
      </li>
      <li class="active">
        <a href="../py-modindex.html" title="Python Module Index"
           >modules</a>
      </li>
      <li class="active">
        <a href="sklearnef.tree.GoodnessOfFit.html" title="sklearnef.tree.GoodnessOfFit"
           accesskey="N">next</a>
      </li>
      <li class="active">
        <a href="generated/sklearnef.tree.DensityTree.transform.html" title="sklearnef.tree.DensityTree.transform"
           accesskey="P">previous</a>
      </li>
    </ul>
              
	    </div>
	  </div>
	</div>
        

	<div class="row-fluid">
      <div class="spc-rightsidebar span3">
        <div class="sphinxsidebarwrapper">
  <h4>Previous topic</h4>
  <p class="topless"><a href="generated/sklearnef.tree.DensityTree.transform.html"
                        title="previous chapter">sklearnef.tree.DensityTree.transform</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="sklearnef.tree.GoodnessOfFit.html"
                        title="next chapter">sklearnef.tree.GoodnessOfFit</a></p>
  <h3>This Page</h3>
  <div>
    <a href="../_sources/generated/sklearnef.tree.SemiSupervisedDecisionTreeClassifier.txt"
       rel="nofollow">Show Source</a>
  </div>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
          <div class="span9">
            
        <div class="bodywrapper">
          <div class="body" id="spc-section-body">
            
  <div class="section" id="sklearnef-tree-semisuperviseddecisiontreeclassifier">
<h1>sklearnef.tree.SemiSupervisedDecisionTreeClassifier<a class="headerlink" href="#sklearnef-tree-semisuperviseddecisiontreeclassifier" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="sklearnef.tree.SemiSupervisedDecisionTreeClassifier">
<em class="property">class </em><tt class="descclassname">sklearnef.tree.</tt><tt class="descname">SemiSupervisedDecisionTreeClassifier</tt><big>(</big><em>criterion='semisupervised'</em>, <em>splitter='semisupervised'</em>, <em>max_depth=None</em>, <em>min_samples_split=2</em>, <em>min_samples_leaf=None</em>, <em>min_weight_fraction_leaf=0.0</em>, <em>max_features=None</em>, <em>random_state=None</em>, <em>max_leaf_nodes=None</em>, <em>min_improvement=0</em>, <em>supervised_weight=0.5</em>, <em>transduction_method='approximate'</em>, <em>transduction_n_knn=5</em>, <em>transduction_tol=0.0001</em>, <em>unsupervised_transformation='scale'</em>, <em>class_weight=None</em><big>)</big><a class="headerlink" href="#sklearnef.tree.SemiSupervisedDecisionTreeClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>A tree for semi-supervised classification.</p>
<p>The tree takes a mix of labelled and unlabelled training samples,
ultimately assigning class labels to the unlabelled data.</p>
<p>Using induction to transduction, a classification tree is trained
representing the findings of the whole training set, labelled as
well as unlabelled.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>splitter</strong> : string, optional (default=&#8221;semisupervised&#8221;)</p>
<blockquote>
<div><p>The strategy used to choose the split at each node. Currently only
&#8220;semisupervised&#8221; is supported, which is a variant of the &#8220;best&#8221;
splitter strategy.</p>
</div></blockquote>
<p><strong>max_features</strong> : int, float, string or None, optional (default=None)</p>
<blockquote>
<div><dl class="docutils">
<dt>The number of features to consider when looking for the best split:</dt>
<dd><ul class="first last simple">
<li>If int, then consider <em class="xref py py-obj">max_features</em> features at each split.</li>
<li>If float, then <em class="xref py py-obj">max_features</em> is a percentage and
<em class="xref py py-obj">int(max_features * n_features)</em> features are considered at each
split.</li>
<li>If &#8220;auto&#8221;, then <em class="xref py py-obj">max_features=sqrt(n_features)</em>.</li>
<li>If &#8220;sqrt&#8221;, then <em class="xref py py-obj">max_features=sqrt(n_features)</em>.</li>
<li>If &#8220;log2&#8221;, then <em class="xref py py-obj">max_features=log2(n_features)</em>.</li>
<li>If None, then <em class="xref py py-obj">max_features=n_features</em>.</li>
</ul>
</dd>
</dl>
<p>Note: the search for a split does not stop until at least one
valid partition of the node samples is found, even if it requires to
effectively inspect more than <tt class="docutils literal"><span class="pre">max_features</span></tt> features.</p>
</div></blockquote>
<p><strong>supervised_weight: float, optional (default=0.5)</strong></p>
<blockquote>
<div><p>Factor balancing the supervised against the un-supervised measures of
split quality. A value of <em class="xref py py-obj">1.0</em> would mean to consider only the
labelled samples, a value of <em class="xref py py-obj">0.0</em> would equal a density tree.
Note that a clean value of <em class="xref py py-obj">1.0</em> is not allowed, at it would lead
to non max-margin splits. Please use the original <tt class="xref py py-obj docutils literal"><span class="pre">sklearn</span></tt>
<em class="xref py py-obj">DecisionTreeClassifier</em> for that effect.</p>
</div></blockquote>
<p><strong>min_improvement</strong> : float (default=0.)</p>
<blockquote>
<div><p>The minimum improvement a split must exhibit to be considered adequate.
One of the strongest parameters for controlling over-fitting in density
trees.</p>
</div></blockquote>
<p><strong>transduction_method</strong> : string (default=&#8221;approximate&#8221;)</p>
<blockquote>
<div><dl class="docutils">
<dt>Transduction method for the label propagation. Choices are:</dt>
<dd><ul class="first last simple">
<li>&#8216;approximate&#8217; for a rough and fast label propagation, whose
complexity depends on the number of tree leaves</li>
<li>&#8216;diffusion&#8217; for a more accurate and slower label propagation,
whose complexity depends on the number of training samples;
can be influenced through the <em class="xref py py-obj">transduction_n_knn</em> and
<em class="xref py py-obj">transduction_tol</em> parameters</li>
</ul>
</dd>
</dl>
</div></blockquote>
<p><strong>transduction_n_knn: int, optional (default=5)</strong></p>
<blockquote>
<div><p>Use this to set the number of k nearest neighbours used to construct the graph
for approximate label transduction. Larger values might better the results but
increase the runtime.</p>
</div></blockquote>
<p><strong>transduction_tol: int, optional (default=1e-4)</strong></p>
<blockquote>
<div><p>Use this to set the error tolerance for the approximate linear equation solver
for approximate label transduction. Smaller values can lead to better results
but increase the runtime.</p>
</div></blockquote>
<p><strong>!TODO: Assert that this is only applied to the non-supervised part of the data.</strong></p>
<blockquote>
<div><p>Maybe by initializing the Splitter later or something? Is this at all possible?</p>
</div></blockquote>
<p><strong>!TODO: Very difficult to achieve such a behaviour. First test with overall PCA and/or</strong></p>
<blockquote>
<div><p>scaling. Might be a more sensible approach.</p>
</div></blockquote>
<p><strong>unsupervised_transformation: string, object or None, optional (default=&#8217;scale&#8217;)</strong></p>
<blockquote>
<div><p>Transformation method for the un-supervised samples (their split
quality measure requires features of equal scale). Choices are:</p>
<blockquote>
<div><ul class="simple">
<li>&#8220;scale&#8221;, in which case the <em class="xref py py-obj">StandardScaler</em> is employed.</li>
<li>Any object which implements the fit() and transform() methods.</li>
<li>None, in which the user is responsible for data normalization.</li>
</ul>
</div></blockquote>
</div></blockquote>
<p><strong>max_depth</strong> : int or None, optional (default=None)</p>
<blockquote>
<div><p>The maximum depth of the tree. If None, then nodes are expanded until
all leaves are pure or until all leaves contain less than
<tt class="docutils literal"><span class="pre">min_samples_split</span></tt> samples.
Ignored if <tt class="docutils literal"><span class="pre">max_leaf_nodes</span></tt> is not None.</p>
</div></blockquote>
<p><strong>min_samples_split</strong> : int, optional (default=2)</p>
<blockquote>
<div><p>The minimum number of samples required to split an internal node.</p>
</div></blockquote>
<p><strong>min_samples_leaf</strong> : int or None, optional (default=None)</p>
<blockquote>
<div><p>The minimum number of samples required to be at a leaf node. Must be
at least as high as the number of features in the training set. If None,
set to the number of features at training time.</p>
</div></blockquote>
<p><strong>min_weight_fraction_leaf</strong> : float, optional (default=0.)</p>
<blockquote>
<div><p>The minimum weighted fraction of the input samples required to be at a
leaf node.</p>
</div></blockquote>
<p><strong>max_leaf_nodes</strong> : int or None, optional (default=None)</p>
<blockquote>
<div><p>Grow a tree with <tt class="docutils literal"><span class="pre">max_leaf_nodes</span></tt> in best-first fashion.
Best nodes are defined as relative reduction in impurity.
If None then unlimited number of leaf nodes.
If not None then <tt class="docutils literal"><span class="pre">max_depth</span></tt> will be ignored.</p>
</div></blockquote>
<p><strong>random_state</strong> : int, RandomState instance or None, optional (default=None)</p>
<blockquote class="last">
<div><p>If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <em class="xref py py-obj">np.random</em>.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<p class="last"><a class="reference internal" href="sklearnef.tree.DensityTree.html#sklearnef.tree.DensityTree" title="sklearnef.tree.DensityTree"><tt class="xref py py-obj docutils literal"><span class="pre">DensityTree</span></tt></a>, <tt class="xref py py-obj docutils literal"><span class="pre">sklearn.tree.DecisionTreeClassifier</span></tt></p>
</div>
<p class="rubric">Notes</p>
<p>A third party fortran library uses its own random number generator, hence the
results of two consecutive training with the same data and same random seed
can differ slightly.</p>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="r5" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[R5]</a></td><td>A. Criminisi, J. Shotton and E. Konukoglu, &#8220;Decision Forests: A 
Unified Framework for Classification, Regression, Density
Estimation, Manifold Learning and Semi-Supervised Learning&#8221;,
Foundations and Trends(r) in Computer Graphics and Vision, Vol. 7,
No. 2-3, pp 81-227, 2012.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="r6" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[R6]</td><td><em>(<a class="fn-backref" href="#id2">1</a>, <a class="fn-backref" href="#id3">2</a>)</em> L. Breiman, and A. Cutler, &#8220;Random Forests&#8221;,
<a class="reference external" href="http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm">http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm</a></td></tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearnef.tree</span> <span class="kn">import</span> <span class="n">SemiSupervisedDecisionTreeClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">SemiSupervisedDecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
<span class="go">array([[ 0.99405824,  0.        ],</span>
<span class="go">       [ 0.99405824,  0.        ],</span>
<span class="go">     ...    </span>
</pre></div>
</div>
<p class="rubric">Attributes</p>
<table border="1" class="docutils">
<colgroup>
<col width="6%" />
<col width="94%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td>tree_</td>
<td>(Tree object) The underlying Tree object.</td>
</tr>
<tr class="row-even"><td>max_features_</td>
<td>(int) The inferred value of max_features.</td>
</tr>
<tr class="row-odd"><td>feature_importances_</td>
<td>(array of shape = [n_features]) The feature importances. The higher, the more important the feature. The importance of a feature is computed as the (normalized) total reduction of the criterion brought by that feature.  It is also known as the Gini importance <a class="reference internal" href="#r6" id="id3">[R6]</a>.</td>
</tr>
<tr class="row-even"><td>n_outputs_</td>
<td>(int) For internal use only. Value does not convey any meaning for SemiSupervisedDecisionTreeClassifiers.</td>
</tr>
<tr class="row-odd"><td>n_classes_</td>
<td>(array of shape = [n_outputs]) For internal use only. Value does not convey the same meaning for SemiSupervisedDecisionTreeClassifiers. First entry holds the count of unique class labels of the tree plus one (for the un-labelled class). All other entries are the same.</td>
</tr>
<tr class="row-even"><td>classes_</td>
<td>(array of shape = [n_outputs, n_classes]) For internal use only. Value does not convey the same meaning for SemiSupervisedDecisionTreeClassifiers: First entry holds the unique class labels of the tree, with the first being the un-labelled class label, which is not used for classification. All other entries are the same.</td>
</tr>
<tr class="row-odd"><td>transduced_proba_</td>
<td>(array of shape [n_unlabelled_samples, n_classes]) The transduced label probabilities for the unlabelled portion of the training set. Only available after fitting the classifier.</td>
</tr>
<tr class="row-even"><td>transduced_labels_</td>
<td>(array of shape [n_unlabelled_samples]) The transduced labels for the unlabelled portion of the training set. Only available after fitting the classifier.</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearnef.tree.SemiSupervisedDecisionTreeClassifier.__init__.html#sklearnef.tree.SemiSupervisedDecisionTreeClassifier.__init__" title="sklearnef.tree.SemiSupervisedDecisionTreeClassifier.__init__"><tt class="xref py py-obj docutils literal"><span class="pre">__init__</span></tt></a>([criterion,&nbsp;splitter,&nbsp;max_depth,&nbsp;...])</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearnef.tree.SemiSupervisedDecisionTreeClassifier.cdf.html#sklearnef.tree.SemiSupervisedDecisionTreeClassifier.cdf" title="sklearnef.tree.SemiSupervisedDecisionTreeClassifier.cdf"><tt class="xref py py-obj docutils literal"><span class="pre">cdf</span></tt></a>(X[,&nbsp;check_input])</td>
<td>Cumulative density function of the learned distribution.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearnef.tree.SemiSupervisedDecisionTreeClassifier.fit.html#sklearnef.tree.SemiSupervisedDecisionTreeClassifier.fit" title="sklearnef.tree.SemiSupervisedDecisionTreeClassifier.fit"><tt class="xref py py-obj docutils literal"><span class="pre">fit</span></tt></a>(X,&nbsp;y[,&nbsp;sample_weight,&nbsp;check_input])</td>
<td>Build a decision tree from the training set (X, y).</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearnef.tree.SemiSupervisedDecisionTreeClassifier.fit_transform.html#sklearnef.tree.SemiSupervisedDecisionTreeClassifier.fit_transform" title="sklearnef.tree.SemiSupervisedDecisionTreeClassifier.fit_transform"><tt class="xref py py-obj docutils literal"><span class="pre">fit_transform</span></tt></a>(X[,&nbsp;y])</td>
<td>Fit to data, then transform it.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearnef.tree.SemiSupervisedDecisionTreeClassifier.get_params.html#sklearnef.tree.SemiSupervisedDecisionTreeClassifier.get_params" title="sklearnef.tree.SemiSupervisedDecisionTreeClassifier.get_params"><tt class="xref py py-obj docutils literal"><span class="pre">get_params</span></tt></a>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearnef.tree.SemiSupervisedDecisionTreeClassifier.goodness_of_fit.html#sklearnef.tree.SemiSupervisedDecisionTreeClassifier.goodness_of_fit" title="sklearnef.tree.SemiSupervisedDecisionTreeClassifier.goodness_of_fit"><tt class="xref py py-obj docutils literal"><span class="pre">goodness_of_fit</span></tt></a>(X[,&nbsp;eval_type,&nbsp;check_input])</td>
<td>Goodness of fit of the learned density distribution.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearnef.tree.SemiSupervisedDecisionTreeClassifier.parse_tree_leaves.html#sklearnef.tree.SemiSupervisedDecisionTreeClassifier.parse_tree_leaves" title="sklearnef.tree.SemiSupervisedDecisionTreeClassifier.parse_tree_leaves"><tt class="xref py py-obj docutils literal"><span class="pre">parse_tree_leaves</span></tt></a>()</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearnef.tree.SemiSupervisedDecisionTreeClassifier.pdf.html#sklearnef.tree.SemiSupervisedDecisionTreeClassifier.pdf" title="sklearnef.tree.SemiSupervisedDecisionTreeClassifier.pdf"><tt class="xref py py-obj docutils literal"><span class="pre">pdf</span></tt></a>(X[,&nbsp;check_input])</td>
<td>Probability density function of the learned distribution.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearnef.tree.SemiSupervisedDecisionTreeClassifier.predict.html#sklearnef.tree.SemiSupervisedDecisionTreeClassifier.predict" title="sklearnef.tree.SemiSupervisedDecisionTreeClassifier.predict"><tt class="xref py py-obj docutils literal"><span class="pre">predict</span></tt></a>(X[,&nbsp;check_input])</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearnef.tree.SemiSupervisedDecisionTreeClassifier.predict_log_proba.html#sklearnef.tree.SemiSupervisedDecisionTreeClassifier.predict_log_proba" title="sklearnef.tree.SemiSupervisedDecisionTreeClassifier.predict_log_proba"><tt class="xref py py-obj docutils literal"><span class="pre">predict_log_proba</span></tt></a>(X)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearnef.tree.SemiSupervisedDecisionTreeClassifier.predict_proba.html#sklearnef.tree.SemiSupervisedDecisionTreeClassifier.predict_proba" title="sklearnef.tree.SemiSupervisedDecisionTreeClassifier.predict_proba"><tt class="xref py py-obj docutils literal"><span class="pre">predict_proba</span></tt></a>(X[,&nbsp;check_input])</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearnef.tree.SemiSupervisedDecisionTreeClassifier.score.html#sklearnef.tree.SemiSupervisedDecisionTreeClassifier.score" title="sklearnef.tree.SemiSupervisedDecisionTreeClassifier.score"><tt class="xref py py-obj docutils literal"><span class="pre">score</span></tt></a>(X,&nbsp;y[,&nbsp;sample_weight])</td>
<td>Returns the mean accuracy on the given test data and labels.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearnef.tree.SemiSupervisedDecisionTreeClassifier.set_params.html#sklearnef.tree.SemiSupervisedDecisionTreeClassifier.set_params" title="sklearnef.tree.SemiSupervisedDecisionTreeClassifier.set_params"><tt class="xref py py-obj docutils literal"><span class="pre">set_params</span></tt></a>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-even"><td><tt class="xref py py-obj docutils literal"><span class="pre">SemiSupervisedDecisionTreeClassifier.transduction_best</span></tt></td>
<td></td>
</tr>
<tr class="row-odd"><td><tt class="xref py py-obj docutils literal"><span class="pre">SemiSupervisedDecisionTreeClassifier.transduction_fast</span></tt></td>
<td></td>
</tr>
<tr class="row-even"><td><tt class="xref py py-obj docutils literal"><span class="pre">SemiSupervisedDecisionTreeClassifier.transduction_optimized</span></tt></td>
<td></td>
</tr>
<tr class="row-odd"><td><tt class="xref py py-obj docutils literal"><span class="pre">SemiSupervisedDecisionTreeClassifier.transduction_optimized_alt</span></tt></td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearnef.tree.SemiSupervisedDecisionTreeClassifier.transform.html#sklearnef.tree.SemiSupervisedDecisionTreeClassifier.transform" title="sklearnef.tree.SemiSupervisedDecisionTreeClassifier.transform"><tt class="xref py py-obj docutils literal"><span class="pre">transform</span></tt></a>(X[,&nbsp;threshold])</td>
<td>Reduce X to its most important features.</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>


          </div>
        </div>
          </div>
        </div>
      </div>
    </div>

    <div class="container container-navbar-bottom">
      <div class="spc-navbar">
        
      </div>
    </div>
    <div class="container">
    <div class="footer">
    <div class="row-fluid">
    <ul class="inline pull-left">
      <li>
        &copy; Copyright 2016, Oskar Maier.
      </li>
      <li>
      Last updated on Sep 18, 2017.
      </li>
      <li>
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.2.3.
      </li>
    </ul>
    </div>
    </div>
    </div>
  </body>
</html>
